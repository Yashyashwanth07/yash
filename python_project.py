# -*- coding: utf-8 -*-
"""Python Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wPT1kzJXPyDMbBxYcgwtONzBgqfpK9fH

# ***Lung Cancer Prediction using Machine Learning Models***

# ***Random Forest Classifier***
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix

# Load the dataset
file_path = '/content/survey lung cancer.csv'
df = pd.read_csv(file_path)

# Encode categorical variables
label_encoder = LabelEncoder()

# Select relevant features for the model
df_encoded = df.copy()

# Apply label encoding to all the categorical columns
for col in df_encoded.columns[:-1]:  # We don't encode the 'Prediction' column yet
    df_encoded[col] = label_encoder.fit_transform(df_encoded[col].astype(str))

# Encode the target 'Prediction' column
df_encoded['Prediction'] = label_encoder.fit_transform(df_encoded['Prediction'])

# Split data into features (X) and target (y)
X = df_encoded.drop('Prediction', axis=1)
y = df_encoded['Prediction']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=40)

# Initialize and train a Random Forest classifier
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

# Calculate accuracy, precision, F1 score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Get the confusion matrix to extract TP, TN, FP, and FN
conf_matrix = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = conf_matrix.ravel()

# Prepare and format the results for user-friendly output
print("Model Performance Summary:")
print("-" * 30)
print(f"Accuracy: {accuracy * 100:.2f}%")
print(f"Precision: {precision * 100:.2f}%")
print(f"F1 Score: {f1:.2f}")
print("\nConfusion Matrix:")
print(f"True Positives (TP): {tp}")
print(f"True Negatives (TN): {tn}")
print(f"False Positives (FP): {fp}")
print(f"False Negatives (FN): {fn}")
print("-" * 30)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
file_path = '/content/survey lung cancer.csv'
df = pd.read_csv(file_path)

# Encode categorical variables
label_encoder = LabelEncoder()

# Select relevant features for the model
df_encoded = df.copy()

# Apply label encoding to all the categorical columns
for col in df_encoded.columns[:-1]:  # We don't encode the 'Prediction' column yet
    df_encoded[col] = label_encoder.fit_transform(df_encoded[col].astype(str))

# Encode the target 'Prediction' column
df_encoded['Prediction'] = label_encoder.fit_transform(df_encoded['Prediction'])

# Split data into features (X) and target (y)
X = df_encoded.drop('Prediction', axis=1)
y = df_encoded['Prediction']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=40)

# Initialize and train a Random Forest classifier
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

# Calculate accuracy, precision, F1 score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Get the confusion matrix to extract TP, TN, FP, and FN
conf_matrix = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = conf_matrix.ravel()

# Prepare and format the results for user-friendly output
print("Model Performance Summary:")
print("-" * 30)
print(f"Accuracy: {accuracy * 100:.2f}%")
print(f"Precision: {precision * 100:.2f}%")
print(f"F1 Score: {f1:.2f}")
print("\nConfusion Matrix:")
print(f"True Positives (TP): {tp}")
print(f"True Negatives (TN): {tn}")
print(f"False Positives (FP): {fp}")
print(f"False Negatives (FN): {fn}")
print("-" * 30)

# Visualization 1: Confusion Matrix Heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred: Negative', 'Pred: Positive'], yticklabels=['Actual: Negative', 'Actual: Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix Heatmap')
plt.show()

# Visualization 2: Feature Importance Plot
feature_importances = rf_model.feature_importances_
plt.figure(figsize=(10, 6))
plt.barh(X.columns, feature_importances)
plt.xlabel('Feature Importance')
plt.title('Feature Importance of Each Feature in Predicting Lung Cancer')
plt.show()

# Visualization 3: ROC Curve
y_probs = rf_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

# Visualization 4: Precision-Recall Curve
precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_probs)
average_precision = average_precision_score(y_test, y_probs)

plt.figure(figsize=(8, 6))
plt.plot(recall_vals, precision_vals, color='blue', lw=2, label=f'Precision-Recall curve (AP = {average_precision:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc='lower left')
plt.show()

"""# ***Decision Trees***"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix

# Load the dataset
file_path = '/content/survey lung cancer.csv'
df = pd.read_csv(file_path)

# Encode categorical variables
label_encoder = LabelEncoder()

# Select relevant features for the model
df_encoded = df.copy()

# Apply label encoding to all the categorical columns except the target 'Prediction'
for col in df_encoded.columns[:-1]:
    df_encoded[col] = label_encoder.fit_transform(df_encoded[col].astype(str))

# Encode the target 'Prediction' column
df_encoded['Prediction'] = label_encoder.fit_transform(df_encoded['Prediction'])

# Split data into features (X) and target (y)
X = df_encoded.drop('Prediction', axis=1)
y = df_encoded['Prediction']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=40)

# Initialize and train a Decision Tree classifier
tree_model = DecisionTreeClassifier(random_state=42)
tree_model.fit(X_train, y_train)

# Make predictions
y_pred = tree_model.predict(X_test)

# Calculate accuracy, precision, F1 score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Get the confusion matrix to extract TP, TN, FP, and FN
conf_matrix = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = conf_matrix.ravel()

# Prepare and format the results for user-friendly output
print("Model Performance Summary:")
print("-" * 30)
print(f"Accuracy: {accuracy * 100:.2f}%")
print(f"Precision: {precision * 100:.2f}%")
print(f"F1 Score: {f1:.2f}")
print("\nConfusion Matrix:")
print(f"True Positives (TP): {tp}")
print(f"True Negatives (TN): {tn}")
print(f"False Positives (FP): {fp}")
print(f"False Negatives (FN): {fn}")
print("-" * 30)

"""# ***Logistic Regression***"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix

# Load the dataset
file_path = '/content/survey lung cancer.csv'
df = pd.read_csv(file_path)

# Encode categorical variables
label_encoder = LabelEncoder()

# Select relevant features for the model
df_encoded = df.copy()

# Apply label encoding to all the categorical columns except the target 'Prediction'
for col in df_encoded.columns[:-1]:
    df_encoded[col] = label_encoder.fit_transform(df_encoded[col].astype(str))

# Encode the target 'Prediction' column
df_encoded['Prediction'] = label_encoder.fit_transform(df_encoded['Prediction'])

# Split data into features (X) and target (y)
X = df_encoded.drop('Prediction', axis=1)
y = df_encoded['Prediction']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=40)

# Initialize and train a Logistic Regression model
logistic_model = LogisticRegression(random_state=42, max_iter=1000)  # Increase max_iter if convergence warning occurs
logistic_model.fit(X_train, y_train)

# Make predictions
y_pred = logistic_model.predict(X_test)

# Calculate accuracy, precision, F1 score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Get the confusion matrix to extract TP, TN, FP, and FN
conf_matrix = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = conf_matrix.ravel()

# Prepare and format the results for user-friendly output
print("Model Performance Summary:")
print("-" * 30)
print(f"Accuracy: {accuracy * 100:.2f}%")
print(f"Precision: {precision * 100:.2f}%")
print(f"F1 Score: {f1:.2f}")
print("\nConfusion Matrix:")
print(f"True Positives (TP): {tp}")
print(f"True Negatives (TN): {tn}")
print(f"False Positives (FP): {fp}")
print(f"False Negatives (FN): {fn}")
print("-" * 30)

"""# ***Support Vector Machine***"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix

# Load the dataset
file_path = '/content/survey lung cancer.csv'
df = pd.read_csv(file_path)

# Encode categorical variables
label_encoder = LabelEncoder()

# Select relevant features for the model
df_encoded = df.copy()

# Apply label encoding to all the categorical columns except the target 'Prediction'
for col in df_encoded.columns[:-1]:
    df_encoded[col] = label_encoder.fit_transform(df_encoded[col].astype(str))

# Encode the target 'Prediction' column
df_encoded['Prediction'] = label_encoder.fit_transform(df_encoded['Prediction'])

# Split data into features (X) and target (y)
X = df_encoded.drop('Prediction', axis=1)
y = df_encoded['Prediction']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=40)

# Initialize and train an SVM classifier
svm_model = SVC(kernel='linear', random_state=42)  # 'linear' kernel; change to 'rbf' or others as needed
svm_model.fit(X_train, y_train)

# Make predictions
y_pred = svm_model.predict(X_test)

# Calculate accuracy, precision, F1 score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Get the confusion matrix to extract TP, TN, FP, and FN
conf_matrix = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = conf_matrix.ravel()

# Prepare and format the results for user-friendly output
print("Model Performance Summary:")
print("-" * 30)
print(f"Accuracy: {accuracy * 100:.2f}%")
print(f"Precision: {precision * 100:.2f}%")
print(f"F1 Score: {f1:.2f}")
print("\nConfusion Matrix:")
print(f"True Positives (TP): {tp}")
print(f"True Negatives (TN): {tn}")
print(f"False Positives (FP): {fp}")
print(f"False Negatives (FN): {fn}")
print("-" * 30)

"""# ***Comparing Different Models***"""

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, f1_score

# Initialize models
models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(),
    "SVM": SVC(),
    "KNN": KNeighborsClassifier()
}

# Evaluate each model
for model_name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    print(f"{model_name} Performance:")
    print(f"Accuracy: {accuracy * 100:.2f}%")
    print(f"Precision: {precision * 100:.2f}%")
    print(f"F1 Score: {f1:.2f}")
    print("-" * 30)